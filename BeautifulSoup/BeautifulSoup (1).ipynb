{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'requests'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Que-1\nurl = 'https://en.wikipedia.org/wiki/Main_Page'\nresponse = requests.get(url)\nhtml_content = response.text\n\n\nresult= BeautifulSoup(html_content, 'html.parser')\n\n\nheaders = []\n\n\nfor tag in range(1, 5):\n    header_tags = result.find_all(f'h{tag}')\n    \n    for header in header_tags:\n        headers.append(header.text.strip())\n\ndf = pd.DataFrame({'Headers': headers})\n\nprint(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Que-2\nurl = 'https://presidentofindia.nic.in/former-presidents.htm'\nresponse = requests.get(url)\nhtml_content = response.text\n\n\nresult= BeautifulSoup(html_content, 'html.parser')\n\ntable = result.find('table', class_='table')\n\nnames = []\nterms_of_office = []\n\nfor row in table.find_all('tr')[1:]:  \n\n    columns = row.find_all('td')\n    name = columns[0].text.strip()\n    term_of_office = columns[1].text.strip()\n    names.append(name)\n    terms_of_office.append(term_of_office)\n\n\ndf = pd.DataFrame({'Name': names, 'Term of Office': terms_of_office})\n\nprint(df)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Que-3\n\n#a)-To scrape the top 10 ODI teams in men's cricket along with the records for matches, points, and rating, you can use the following code:\n\n\nurl = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\nteam_data = []\ntable = soup.find(\"table\", class_=\"table\")\nrows = table.find_all(\"tr\")\n\nfor row in rows[1:11]:\n  cells= row.find_all(\"td\")\n  team= cells[1].text.strip()\n  matches= cells[2].text.strip()\n  points= cells[3].text.strip()\n  rating= cells[4].text.strip()\n  team_data.append([team, matches, points, rating])\n\ndf = pd.DataFrame(team_data, columns=[\"Team\", \"Matches\", \"Points\", \"Rating\"])\nprint(df)\n\n\n#b)-To scrape the top 10 ODI batsmen along with the records of their team and rating, you can use the following code:\n\nurl = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\nbatsman_data = []\ntable= soup.find(\"table\", class_=\"table\")\nrows = table.find_all(\"tr\")\n\nfor row in rows[1:11]:\n  cells= row.find_all(\"td\")\n  batsman= cells[1].text.strip()\n  team= cells[2].text.strip()\n  rating= cells[3].text.strip()\n  batsman_data.append([batsman, team, rating])\n\ndf = pd.DataFrame(batsman_data, columns=[\"Batsman\", \"Team\", \"Rating\"])\nprint(df)\n\n\n#c)-To scrape the top 10 ODI bowlers along with the records of their team and rating, you can use the following code:\n\nurl= \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\nresponse = requests.get(url)\nsoup= BeautifulSoup(response.content, \"html.parser\")\n\nbowler_data = []\ntable= soup.find(\"table\", class_=\"table\")\nrows = table.find_all(\"tr\")\n\nfor row in rows[1:11]:\n  cells= row.find_all(\"td\")\n  bowler= cells[1].text.strip()\n  team= cells[2].text.strip()\n  rating= cells[3].text.strip()\n  bowler_data.append([bowler, team, rating])\n\ndf= pd.DataFrame(bowler_data, columns=[\"Bowler\", \"Team\", \"Rating\"])\nprint(df)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Que-5\nurl = 'https://www.cnbc.com/world/?region=world'\nresponse = requests.get(url)\nhtml_content = response.text\n\nresult= BeautifulSoup(html_content, 'html.parser')\n\n\nheadlines = []\ntimes = []\nnews_links = []\n\n\narticles = result.find_all('div', class_='Card-title')\n\nfor article in articles:\n    headline = article.find('a').text.strip()\n    headlines.append(headline)\n    \n    time = article.find_next('div', class_='Card-time').text.strip()\n    times.append(time)\n    \n    news_link = article.find('a')['href']\n    news_links.append(news_link)\n\n\ndf = pd.DataFrame({'Headline': headlines, 'Time': times, 'News Link': news_links})\n\n\nprint(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Que-6\nurl = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n\nresponse = requests.get(url)\n\nsoup = BeautifulSoup(response.content, 'html.parser')\ntitles= []\nauthors= []\npublished_dates= []\npaper_urls= []\n\narticles = soup.find_all('div', class_='article-info')\n\nfor article in articles:\n    title = article.find('a', class_='highwire-cite-linked-title').text.strip()\n    titles.append(title)\n    \n    author = article.find('div', class_='highwire-citation-authors').text.strip()\n    authors.append(author)\n    \n    published_date = article.find('div', class_='tocEPubDate').text.strip()\n    published_dates.append(published_date)\n    \n    paper_url = article.find('a', class_='highwire-cite-linked-title')['href']\n    paper_urls.append(paper_url)\n\n\ndata = { 'Paper Title': titles,  'Authors': authors,'Published Date': published_dates,'Paper URL': paper_urls}\n\ndf = pd.DataFrame(data)\n\nprint(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Que-7\nurl = 'https://www.dineout.co.in/delhi-restaurants'\nresponse = requests.get(url)\nhtml_content = response.text\nresult = BeautifulSoup(html_content, 'html.parser')\n\nrestaurant_names= []\ncuisines= []\nlocations= []\nratings= []\nimage_urls= []\n\nrestaurant_cards = result.find_all('div', class_='restnt-card')\n\n\nfor card in restaurant_cards:\n    \n    restaurant_name = card.find('div', class_='restnt-info').h2.text.strip()\n    restaurant_names.append(restaurant_name)\n    \n    # Cuisine\n    cuisine= card.find('div', class_='restnt-info').p.text.strip()\n    cuisines.append(cuisine)\n    \n    # Location\n    location= card.find('div', class_='restnt-info').find('div', class_='restnt-loc').text.strip()\n    locations.append(location)\n    \n    # Ratings\n    rating= card.find('div', class_='restnt-rating').text.strip()\n    ratings.append(rating)\n    \n    # Image URL\n    image_url= card.find('div', class_='img-dtl')['style'].split(\"url('\")[1].split(\"')\")[0]\n    image_urls.append(image_url)\n\n\ndf = pd.DataFrame({ 'Restaurant Name': restaurant_names,'Cuisine': cuisines,\n    'Location': locations, 'Ratings': ratings, 'Image URL': image_urls})\n\nprint(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}